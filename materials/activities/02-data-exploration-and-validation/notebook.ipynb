{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Validation\n",
    "\n",
    "In this exercise we will cover how to use Ibis, Pandas, and Pandera to explore, tidy, and validate the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - load data from SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `ibis` to load the data from SQL into a pandas dataframe.\n",
    "\n",
    "üö® Only load the first 10,000 rows. This will speed our our ETL and testing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first exercise we used SQLAlchemy to interact with SQL. Ibis is another Python package for interacting with SQL databases. Ibis is specially designed for analytics workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ibis\n",
    "\n",
    "# Set up ibis for reading data\n",
    "con = ibis.postgres.connect(\n",
    "    user=\"posit\",\n",
    "    password=os.environ[\"CONF23_DB_PASSWORD\"],\n",
    "    host=os.environ[\"CONF23_DB_HOST\"],\n",
    "    port=5432,\n",
    "    database=\"conf23_python\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the business license data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_raw = con.table(name=\"business_license_raw\").limit(10_000).to_pandas()\n",
    "business_license_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the food inspection data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_inspection_raw = con.table(name=\"food_inspection_raw\").limit(10_000).to_pandas()\n",
    "food_inspection_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Explore the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin exploring the data. You will want to understand.\n",
    "\n",
    "- What columns exist in the data?\n",
    "- How do the two data sets relate to one another?\n",
    "- What is the type of each column (e.g. string, number, category, date)?\n",
    "- Which columns could be useful for the model.\n",
    "- What is the cardinality of categorical data?\n",
    "- Is all of the data in scope?\n",
    "- What steps will I need to perform to clean the data?\n",
    "\n",
    "üö® We are not performing feature engineering at this stage. But it is a good time to start thinking about what features you can create from the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business license data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of business locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common license types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do businesses have multiple licenses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does each license only one row in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does all the data relate to Chicago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Food inspection data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different risk levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common facility types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 3 - Tidy Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a basic understanding of the data, the next step is to tidy the data. Create a new notebook that:\n",
    "\n",
    "- Reads in the raw data from the postgres database.\n",
    "- Tidy's the dataset.\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Remove unnecessary rows.\n",
    "- Remove unnecessary columns."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See notebook [example/02-etl-data-validation/notebook.ipynb](../example/02-etl-data-validation/notebook.ipynb) for examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business license data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_tidy = business_license_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data cleaning steps here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_tidy = business_license_tidy.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Food inspection data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_inspection_tidy = food_inspection_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example:\n",
    "# food_inspection_tidy = food_inspection_tidy.loc[food_inspection_tidy[\"city\"] == \"CHICAGO\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your data cleaning steps here..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_inspection_tidy = food_inspection_tidy.reset_index(drop=True)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 4 - Validate Data (Quick Start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous activity we tidied the dataset. For some projects, this may be enough. However, for this project we plan to refresh the data on a regular basis. We would like to gain additional comfort that the data we are using is correct. Data validation can help prove that our data tidying was correct, and find any potential issues if the upstream data changes.\n",
    "\n",
    "[Pandera](https://pandera.readthedocs.io/en/stable/) is a Python library for validating Pandas dataframes. There are two steps:\n",
    "\n",
    "1. Define a schema for your data:\n",
    "   - Define the type for each column\n",
    "   - Confirm if null values are allowed\n",
    "   - Define custom checks\n",
    "2. Run your data through the schema validator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Take 5 minutes, and work through quick start section of the Pandera Docs: https://pandera.readthedocs.io/en/stable/index.html#quick-start."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "\n",
    "# data to validate\n",
    "df = pd.DataFrame({\n",
    "    \"column1\": [1, 4, 0, 10, 9],\n",
    "    \"column2\": [-1.3, -1.4, -2.9, -10.1, -20.4],\n",
    "    \"column3\": [\"value_1\", \"value_2\", \"value_3\", \"value_2\", \"value_1\"],\n",
    "})\n",
    "\n",
    "# define schema\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, checks=pa.Check.le(10)),\n",
    "    \"column2\": pa.Column(float, checks=pa.Check.lt(-1.2)),\n",
    "    \"column3\": pa.Column(str, checks=[\n",
    "        pa.Check.str_startswith(\"value_\"),\n",
    "        # define custom checks as functions that take a series as input and\n",
    "        # outputs a boolean or boolean Series\n",
    "        pa.Check(lambda s: s.str.split(\"_\", expand=True).shape[1] == 2)\n",
    "    ]),\n",
    "})\n",
    "\n",
    "validated_df = schema(df)\n",
    "print(validated_df)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 5 - Validate Data (Real Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understand how Pandera works, lets validate our tidy data! In your notebook where you tidy the data, create Schema to validate both data sets.\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Most of the columns have null values.\n",
    "- Use the `coerce` keyword option to automatically convert columns to the correct type.\n",
    "- For categorical data, confirm that only the expected categories exist.\n",
    "- Think about custom checks that you can add to validate the data.\n",
    "\n",
    "Once your data is validated, write the validated data back to the SQL database.\n",
    "\n",
    "üö® Please prefix any tables you create with your name! For example:\n",
    "\n",
    "- `sam_business_license_validated`\n",
    "- `sam_food_inspections_validated`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See notebook [example/02-etl-data-validation/notebook.ipynb](../example/02-etl-data-validation/notebook.ipynb) for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 6 - Publish the Solution notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publish your Jupyter Notebook to Connect and schedule it to re-run every Sunday at 3:00 AM. This time, make you are using a `requirements.txt` and a virtual environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Navigate to the correct directory\n",
    "cd ~/ds-workflows-python/materials/solutions/02-etl-data-validation/\n",
    "\n",
    "# Create a virtual environment\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "python -m pip install upgrade pip wheel setuptools\n",
    "python -m pip install -r requirements.txt\n",
    "\n",
    "# Deploy the notebook\n",
    "rsconnect deploy notebook --title \"02 - Data Validation\" notebook.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
