{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Exploration and Validation\n",
    "\n",
    "In this exercise we will cover how to use Ibis, Pandas, and Pandera to explore, tidy, and validate the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - load data from SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Use `ibis` to load the data from SQL into a pandas dataframe.\n",
    "- üö® Only load the first 50,000 rows. This will speed our our ETL and testing."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the first exercise we used SQLAlchemy to interact with SQL. Ibis is another Python package for interacting with SQL databases. Ibis is specially designed for analytics workloads."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import ibis\n",
    "\n",
    "# Set up ibis for reading data\n",
    "con = ibis.postgres.connect(\n",
    "    user=\"posit\",\n",
    "    password=os.environ[\"CONF23_DB_PASSWORD\"],\n",
    "    host=os.environ[\"CONF23_DB_HOST\"],\n",
    "    port=5432,\n",
    "    database=\"conf23_python\"\n",
    ")\n",
    "\n",
    "con"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "row_limit = 50_000"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the business license data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_raw = con.table(name=\"business_license_raw\") \\\n",
    "    .limit(row_limit) \\\n",
    "    .to_pandas()\n",
    "    \n",
    "business_license_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load the food inspection data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "food_inspection_raw = con.table(name=\"food_inspection_raw\") \\\n",
    "    .limit(row_limit) \\\n",
    "    .to_pandas()\n",
    "    \n",
    "food_inspection_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "üí° See the `ibis` docs for all of the different methods you can use to modify your SQL query: <https://ibis-project.org/tutorials/ibis-for-pandas-users>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For example, only get rows `JUICE BAR` and sort by `inspection_date`\n",
    "table = con.table(name=\"food_inspection_raw\")\n",
    "table = table.filter([table.dba_name.upper() == \"JUICE BAR\"])\n",
    "table = table.order_by([\"inspection_date\"])\n",
    "table.to_pandas()\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - Explore the data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Begin exploring the data. You will want to understand.\n",
    "\n",
    "- What columns exist in the data?\n",
    "- How do the two data sets relate to one another?\n",
    "- What is the type of each column (e.g. string, number, category, date)?\n",
    "- Which columns could be useful for the model.\n",
    "- What is the cardinality of categorical data?\n",
    "- Is all of the data in scope?\n",
    "- What steps will I need to perform to clean the data?\n",
    "\n",
    "üö® We are not performing feature engineering at this stage. But it is a good time to start thinking about what features you can create from the data."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Business license data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Distribution of business locations:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Most common license types:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Do businesses have multiple licenses?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does each license only one row in the table?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Does all the data relate to Chicago?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Food inspection data "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the different risk levels?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common violations?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common outcomes?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What are the most common facility types?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 3 - Tidy Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you have a basic understanding of the data, the next step is to tidy the data.\n",
    "\n",
    "**Tip**\n",
    "\n",
    "Use multiple cursors in VS Code to easily edit many lines at the same time (<https://code.visualstudio.com/docs/getstarted/tips-and-tricks#_column-box-selection>)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See solution 2 notebook for examples."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Business license data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_tidy = business_license_raw.copy()\n",
    "business_license_tidy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the tidy data to only keep the state of `IL`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter the tidy data to only keep the city of `CHICAGO`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert the `conditional_approval` column from a `str` to a `bool` value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_tidy[\"conditional_approval\"].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Drop the \"location\" column, the same data is already stored in the `latitude` and `longitude` columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reset the index\n",
    "business_license_tidy = business_license_tidy.reset_index(drop=True)\n",
    "business_license_tidy"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 4 - Validate Data (Quick Start)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the previous activity we tidied the dataset. For some projects, this may be enough. However, for this project we plan to refresh the data on a regular basis. We would like to gain additional comfort that the data we are using is correct. Data validation can help prove that our data tidying was correct, and find any potential issues if the upstream data changes.\n",
    "\n",
    "[Pandera](https://pandera.readthedocs.io/en/stable/) is a Python library for validating Pandas dataframes. There are two steps:\n",
    "\n",
    "1. Define a schema for your data. For example:\n",
    "   - Define the type for each column\n",
    "   - Confirm if null values are allowed\n",
    "   - Define custom checks\n",
    "2. Run your data through the schema validator."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You will find these links useful when defining your schema:\n",
    "\n",
    "- List of built in checks: https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.checks.Check.html#pandera.api.checks.Check\n",
    "- List of schema level options: https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.pandas.container.DataFrameSchema.html\n",
    "\n",
    "Take a few minutes and play around with the example below:\n",
    "\n",
    "- Can you run the code as is?\n",
    "- Try channging some of the values in the `DataFrame` so that the schema validation fails.\n",
    "- Try updating the schema so that it passes again."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import pandera as pa\n",
    "\n",
    "# data to validate\n",
    "df = pd.DataFrame({\n",
    "    \"column1\": [1, 11, 0, 10, 9],\n",
    "    \"column2\": [-1.3, -1.4, -2.9, -10.1, -5.2],\n",
    "    \"column3\": [\"value_1\", \"value_2\", \"value_3\", \"value_2\", \"value_1\"],\n",
    "})\n",
    "\n",
    "df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define schema\n",
    "schema = pa.DataFrameSchema({\n",
    "    \"column1\": pa.Column(int, checks=pa.Check.le(11)),\n",
    "    \"column2\": pa.Column(float, checks=pa.Check.lt(-1.2)),\n",
    "    \"column3\": pa.Column(str, checks=[\n",
    "        pa.Check.str_startswith(\"value_\"),\n",
    "        # define custom checks as functions that take a series as input and\n",
    "        # outputs a boolean or boolean Series\n",
    "        pa.Check(lambda s: s.str.split(\"_\", expand=True).shape[1] == 2)\n",
    "    ]),\n",
    "})\n",
    "\n",
    "schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "validated_df = schema(df)\n",
    "validated_df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 5 - Validate Data (Real Data)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that you understand how Pandera works, lets validate our tidy data! In your notebook where you tidy the data, create Schema to validate both data sets. There are a lot of columns in this data, so we will focus on validating just a few interesting and key rows.\n",
    "\n",
    "Tips:\n",
    "\n",
    "- Most of the columns have null values.\n",
    "- Use the `nullable` keyword to allow for missing values.\n",
    "- Use the `coerce` keyword option to automatically convert columns to the correct type."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See the solution 2 notebook for examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "business_license_tidy[[\"city\", \"zip_code\", \"license_start_date\", \"latitude\"]].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write a validation that validates the following columns:\n",
    "#\n",
    "# - `city` is always equal to \"CHICAGO\"\n",
    "# - `latitude` is between 38 and 44 (tip, use between)\n",
    "# - `license_start_date` is a date type (tip, use coerse and pa.DateTime)\n",
    "# - `zip_code` is in a valid format (tip, use a lambda)\n",
    "\n",
    "# These links will help you find the built in checks:\n",
    "#\n",
    "# - List of built in checks: https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.checks.Check.html#pandera.api.checks.Check\n",
    "# - List of schema level options: https://pandera.readthedocs.io/en/stable/reference/generated/pandera.api.pandas.container.DataFrameSchema.html\n",
    "\n",
    "business_license_schema = pa.DataFrameSchema(\n",
    "    strict=False,\n",
    "    columns={\n",
    "        \"city\": pa.Column(),\n",
    "        \"zip_code\": pa.Column(),\n",
    "        \"license_start_date\": pa.Column(),\n",
    "        \"latitude\": pa.Column(),\n",
    "    }\n",
    ")\n",
    "\n",
    "business_license_validated = business_license_schema.validate(business_license_tidy)\n",
    "business_license_validated"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Activity 6 - Publish the Solution notebook"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Publish the solution notebook to Posit Connect.\n",
    "    - The solution notebook will read, tidy, and validate both data sets.\n",
    "- Share the notebook with the rest of the workshop.\n",
    "- Schedule the notebook to run once every week."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "# Navigate to the correct directory\n",
    "cd ~/ds-workflows-python/materials/solutions/02-etl-data-validation/\n",
    "\n",
    "# Create a virtual environment\n",
    "# Use our alias!\n",
    "py-venv\n",
    "python -m pip install -r requirements.txt\n",
    "\n",
    "# Deploy the notebook\n",
    "rsconnect deploy notebook --title \"02 - Chicago Food Inspections - Data Validation\" notebook.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
