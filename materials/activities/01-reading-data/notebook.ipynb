{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "In this exercise we will cover how to use pandas to read data from external data sources. To perform our analysis, we will need to use two different data sets:\n",
    "\n",
    "1. Business licenses data: <https://data.cityofchicago.org/Community-Economic-Development/Business-Licenses/r5kz-chrr>\n",
    "2. Food inspections data: <https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5>\n",
    "\n",
    "Both data sets are hosted on <https://data.cityofchicago.org>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - read data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”„ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Explore the two data sources.\n",
    "- Can you load the data into pandas?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âœ… Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The City of Chicago data portal uses:\n",
    "\n",
    "> The Socrata Open Data API (SODA) provides programmatic access to this dataset including the ability to filter, query, and aggregate data.\n",
    "\n",
    "There is a Python package to interact with SODA, but it is no longer maintained: <https://github.com/xmunoz/sodapy>.\n",
    "\n",
    "Instead of using the Python library, we can call the SODA API directly. Consulting the documentation provides us with some examples how how to use <https://dev.socrata.com/foundry/data.cityofchicago.org/4ijn-s7e5>.\n",
    "\n",
    "For example, we can use `curl` to request the data in JSON form. This has a few problems though:\n",
    "\n",
    "- The data is in JSON. We can work with this, but CSV may be more convenient.\n",
    "- We are using the shell instead of Python\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%sh\n",
    "curl 'https://data.cityofchicago.org/resource/r5kz-chrr.json?$limit=10'"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can instead use Python and Pandas to make the request. Pandas has a built in method to read CSV data directly from a URL. So our first task will be to construct the URL in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "\n",
    "\n",
    "base_url = \"https://data.cityofchicago.org\"\n",
    "\n",
    "# Note the .csv extension\n",
    "path = \"resource/r5kz-chrr.csv\"\n",
    "\n",
    "# To make our code easier to read we can define the parameters in a dict. To know\n",
    "# what parameters are available you must consult the docs: https://dev.socrata.com/docs/queries/\n",
    "params = {\n",
    "    \"$order\": \"id\", \n",
    "    \"$limit\": 5\n",
    "}\n",
    "\n",
    "# Then use an f-string to construct the URL. You can use the built in urlencode\n",
    "# function to correctly format the params.\n",
    "url = f\"{base_url}/{path}?{urlencode(params)}\"\n",
    "url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then pass in the newly constructed URL directly to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "df = pd.read_csv(url)\n",
    "df"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - write data to SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”„ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save the raw data to the Postgres SQL database so that we do not need to hit the API every time we need to interact with the raw data.\n",
    "- You can connect to the database using the following credentials:\n",
    "  - host: `database.conf23workflows.training.posit.co`\n",
    "  - user: `posit`\n",
    "  - password: ???\n",
    "  - database: `conf23_python`\n",
    "\n",
    "ðŸš¨ Please prefix any tables you create with your name! For example:\n",
    "\n",
    "- `sam_business_license_raw`\n",
    "- `sam_food_inspections_raw`\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âœ… Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to interact with SQL databases in Python. For writing data, we prefer to use [SQLAlchemy](https://docs.sqlalchemy.org/en/14/dialects/postgresql.html) with Pandas. You will need to make sure you have the following packages installed.\n",
    "\n",
    "You will first need to create a connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"CONF23_DB_HOST\"]\n",
    "os.environ[\"CONF23_DB_PASSWORD\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "db_user = \"posit\"\n",
    "db_password = os.environ[\"CONF23_DB_PASSWORD\"]\n",
    "db_host = os.environ[\"CONF23_DB_HOST\"]\n",
    "db_port = 5432\n",
    "db_database = \"conf23_python\"\n",
    "engine = create_engine(f\"postgresql+psycopg2://{db_user}:{db_password}@{db_host}/{db_database}\")\n",
    "engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then use pandas built in SQL functions to write data to SQL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "table_name = \"samedwardes_business_license_test\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_sql(table_name, engine, if_exists=\"replace\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that it worked by reading the data from SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    data_from_sql = pd.read_sql(text(f\"SELECT * FROM {table_name}\"), conn)\n",
    "\n",
    "data_from_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - put it all together"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”„ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Clean up your code from activity 1 to pull both datasets from the City of Chicago into pandas dataframes\n",
    "- Write both dataframes into the Postgres database.\n",
    "\n",
    "ðŸš¨ Writing data to postgres can be slow. Do not insert all of the rows in one go. Instead you should write a loop that inserts 10,000 rows at a time.\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âœ… Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [materials/example/01-etl-raw-data/notebook.ipynb](../example/01-etl-raw-data/notebook.ipynb) for a complete solution."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 4 - Publish the notebook to Connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ðŸ”„ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Publish your Jupyter Notebook to Connect and schedule it to re-run every Sunday at 2:00 AM.\n",
    "\n",
    "**Tips**\n",
    "\n",
    "- You will need to create an API key.\n",
    "  - Read this page to learn how to create an API key: https://docs.posit.co/connect/user/api-keys/\n",
    "  - Export the API key as environment variable in your `~/.bashrc`\n",
    "- Export a `CONNECT_SERVER` environment variable\n",
    "\n",
    "\n",
    "```bash\n",
    "# ~/.bashrc\n",
    "export CONNECT_SERVER=\"https://connect.conf23workflows.training.posit.co\"\n",
    "export CONNECT_API_KEY=\"xxx\"\n",
    "```\n",
    "\n",
    "Note that in this workshop, we have set `CONNECT_SERVER` as a global environment variable for everyone. You will still need to set your own API key. You can check what is already set by running:\n",
    "\n",
    "```bash\n",
    "env | grep CONNECT\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### âœ… Solution"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```bash\n",
    "cd materials/your-work/activity-1\n",
    "rsconnect deploy notebook --title \"01 - YOUR NAME - Raw Data ETL\" notebook.ipynb\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
