{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading data\n",
    "\n",
    "In this exercise we will cover how to use pandas to read data from external data sources. To perform our analysis, we will need to use two different data sets:\n",
    "\n",
    "1. Business licenses data: <https://data.cityofchicago.org/Community-Economic-Development/Business-Licenses/r5kz-chrr>\n",
    "2. Food inspections data: <https://data.cityofchicago.org/Health-Human-Services/Food-Inspections/4ijn-s7e5>\n",
    "\n",
    "Both data sets are hosted on <https://data.cityofchicago.org>."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 1 - read data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Download the **business license** data\n",
    "- Convert the data into a pandas dataframe"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The City of Chicago data portal uses makes data available over an API. The API has lots of features, you can read more about how to use it here: <https://dev.socrata.com/foundry/data.cityofchicago.org/r5kz-chrr>.\n",
    "\n",
    "\n",
    "To download the data, many persons first instict is to download via:\n",
    "\n",
    "- Clicking through your web browser.\n",
    "- Via the curl command in the terminal.\n",
    "\n",
    "```bash\n",
    "curl 'https://data.cityofchicago.org/resource/r5kz-chrr?$limit=10'\n",
    "```\n",
    "\n",
    "There is a better way though! Using base Python and pandas we can construct a URL, and convert it directly into a dataframe. Pandas has a built in method to read CSV data directly from a URL. So our first task will be to construct the URL in Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from urllib.parse import urlencode\n",
    "\n",
    "base_url = \"https://data.cityofchicago.org\"\n",
    "\n",
    "# Note the .csv extension\n",
    "path = \"resource/r5kz-chrr.csv\"\n",
    "\n",
    "# To make our code easier to read we can define the parameters in a dict. To know\n",
    "# what parameters are available you must consult the docs: https://dev.socrata.com/docs/queries/\n",
    "params = {\n",
    "    \"$order\": \"id\", \n",
    "    \"$limit\": 500\n",
    "}\n",
    "\n",
    "# Then use an f-string to construct the URL. You can use the built in urlencode\n",
    "# function to correctly format the params.\n",
    "url = f\"{base_url}/{path}?{urlencode(params)}\"\n",
    "url"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can then pass in the newly constructed URL directly to Pandas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "business_license_raw = pd.read_csv(url)\n",
    "business_license_raw"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 2 - write data to SQL"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save `business_license_raw` to the Postgres SQL database.\n",
    "- This way, we do not need to hit the API every time we need to interact with the raw data.\n",
    "- üö® Please prefix any tables you create with your name! For example: `sam_edwardes_business_license_raw`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are many different ways to interact with SQL databases in Python. For writing data, we prefer to use [SQLAlchemy](https://docs.sqlalchemy.org/en/14/dialects/postgresql.html) with Pandas. You will need to make sure you have the following packages installed.\n",
    "\n",
    "You will first need to create a connection to the database."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from sqlalchemy import create_engine, text\n",
    "\n",
    "db_user = \"posit\"\n",
    "db_password = os.environ[\"CONF23_DB_PASSWORD\"]\n",
    "db_host = os.environ[\"CONF23_DB_HOST\"]\n",
    "db_port = 5432\n",
    "db_database = \"conf23_python\"\n",
    "engine = create_engine(f\"postgresql+psycopg2://{db_user}:{db_password}@{db_host}/{db_database}\")\n",
    "engine"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Give the table a unique name, prefixed with your name (e.g. `sam_edwardes_business_license_raw`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use the build in `DataFrame.to_sql` to write the data to Postgres (<https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.to_sql.html>)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can verify that it worked by reading the data from SQL:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with engine.begin() as conn:\n",
    "    data_from_sql = pd.read_sql(text(f\"SELECT * FROM {table_name}\"), conn)\n",
    "\n",
    "data_from_sql"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Task 3 - Publish the solution notebook to Connect"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üîÑ Task"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Publish the solution notebook to Posit Connect.\n",
    "- Share the notebook with the rest of the workshop.\n",
    "- Schedule the notebook to run once every week.\n",
    "- üö® We are going to publish the solution notebook, because it reads and writes the data for both tables that we require."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### üßë‚Äçüíª Code"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- First, lets take a look at the solution. You can find it in this directory: `~/ds-workflows-python/materials/solutions/01-etl-raw-data`.\n",
    "- Notice that we have a requirements.txt file for a virtual environment. For every content we deploy to Connect, we will create a virtual environment."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run the following code from the terminal:\n",
    "\n",
    "```bash\n",
    "# Deactivate your current virtual environment\n",
    "deactivate\n",
    "\n",
    "# Navigate to the correct directory\n",
    "cd ~/ds-workflows-python/materials/solutions/01-etl-raw-data/\n",
    "\n",
    "# Create a virtual environment\n",
    "python -m venv .venv\n",
    "source .venv/bin/activate\n",
    "python -m pip install --upgrade pip wheel setuptools\n",
    "\n",
    "# Install all of the requirements\n",
    "python -m pip install -r requirements.txt\n",
    "\n",
    "# Check that you have the required environment variables set\n",
    "echo $CONNECT_SERVER\n",
    "echo $CONNECT_API_KEY\n",
    "\n",
    "# Publish the notebook\n",
    "rsconnect deploy notebook --title \"01 - Raw Data ETL\" notebook.ipynb"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Pro Tip**\n",
    "\n",
    "Create an alias:\n",
    "\n",
    "```bash\n",
    "alias py-venv='python -m venv .venv && source .venv/bin/activate && python -m pip install --upgrade pip wheel setuptools'\n",
    "```\n",
    "\n",
    "Instead of typing all of the commands above, you can use this shortcut to create and activate a virtual environment.\n",
    "\n",
    "```bash\n",
    "py-venv\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
